% ENORMOUS credit for the foundational formatting 
%   of these notes goes to Patrick Lei. 
% Check out his fantastic course notes
%   here: https://git.snopyta.org/abstract/course-notes
% and his website 
%   here: https://www.math.columbia.edu/~plei/index.html

\documentclass[twoside, 10pt]{article}
\usepackage{bbnotes}
\geometry{margin=2cm}

\newcommand{\Ker}{\text{Ker}}

\definecolor{darkblue}{RGB}{0,0,128}
\definecolor{darkred}{RGB}{128,0,0}
\definecolor{darkyellow}{RGB}{96,96,0}
\definecolor{darkgreen}{RGB}{0,128,0}
\definecolor{darkdarkred}{RGB}{64,0,0}
    
% \lstset
% {
%     basicstyle=\ttfamily\scriptsize, 
%     breaklines=true,
%     postbreak=\mbox{\textcolor{darkdarkred}{$\hookrightarrow$}\space},
%     showstringspaces=false
%     keywordstyle = [1]\bfseries\color{darkred},
%     keywordstyle = [2]\itshape\color{darkgreen},
%     keywordstyle = [3]\sffamily\color{darkblue},
%     keywordstyle = [4]\color{darkyellow},
% }

\fancypagestyle{firstpage}
{
   \fancyhf{}
   \fancyfoot[R]{\itshape Page \thepage\ of \pageref{LastPage}}
   \renewcommand{\headrulewidth}{0pt}
}


\fancypagestyle{pages}
{
    \fancyhead[C]{\scshape Math 412}
    \fancyhead[L]{\scshape Ben Burns}
    \fancyhead[R]{\scshape Spring 2022}
    \renewcommand{\headrulewidth}{0.1pt}
}

\newcommand{\F}{\mathbb{F}}

\pagestyle{pages}

\title{Math 412: Rings and Modules}
\author{Taught by Jenia Tevelev \\ Scribed by Ben Burns}
\affil{UMass Amherst}
\date{Spring 2022}

\begin{document}

    \maketitle\thispagestyle{firstpage}

\tableofcontents

\section{Rings and Fields}

\begin{defn}
        A Ring $R$ is a set with 2 binary operations $+$ and $\cdot$ that satisfy the following axioms
        \begin{enumerate}
            \item $(R, +)$ is an abelian group: associative, commutative, existence of identity and inverses
            \item Multiplication is associative 
            \item $\forall a, b, c \in R : a\cdot (b + c) = a\cdot b + a\cdot c$ (left distributive) and $(a + b) \cdot c = a\cdot c + b\cdot c$ (right distributive)
        \end{enumerate}
\end{defn}

\begin{defn}
    A subset $S$ of a ring $R$ is called a subring if $S$ is a ring with respect to the binary operations of $R$
\end{defn}

\begin{defn}
    A ring $R$ is commutative if multiplication is also commutative
\end{defn}

\begin{rmk}
    $(R, \cdot)$ is almost never a ring since 0 (the general additive identity) is almost never invertible with respect to $\cdot$
\end{rmk}

\begin{exm}[Non-commutative rings] 
    $Mat_n(\R)$ with generic element, addition, and multiplcation defined as\\
    $A = \begin{pmatrix}
            a_{11} & \ldots & a_{1n}\\
            \vdots & \ddots & \vdots\\
            a_{n1} & \ldots & a_{nn}\\
        \end{pmatrix} \in Mat_n(\R)$\\
    $(a_{ij}) + (b_{ij}) = a_{ij} + b_{ij}$\\
    $\begin{pmatrix}
        a_{i1}  & \ldots & a_{in}\\
    \end{pmatrix} \cdot \begin{pmatrix}
        b_{1j}\\
        \vdots\\
        b_{nj}\\
    \end{pmatrix} = \begin{pmatrix}
        a_{i1}b_{1j} + \ldots + a{in}b_{nj}\\
    \end{pmatrix}$
\end{exm}
%Todo: find counterexample

\begin{exm}[Rings of functions]
    $F = \{f | f: \R \to \R\}$\\
    $(f + g)(x) = f(x) + g(x)$\\
    $(f\cdot g)(x) = f(x)g(x)$
\end{exm}

\begin{defn}
    $R$ is a ring with unity 1 if $\forall a \in R: a\cdot 1 = 1\cdot a$
\end{defn}

Note that rings don't necessarily have unity. For example, $(2\Z, + , \cdot)$ has no unity, but satisfies all ring axioms

\begin{rmk}
    $(\Z_n, +)$ is  cyclic abelian group with generator 1. 1 is also unity for modular multiplication
\end{rmk}

\begin{defn}[Direct Product of Rings]
    For $R, S$, rings, we define the direct product of $R$ and $S$\\
    $R\times S = \{(r, s) | r\in R s\in S\}$. \\
    $(r, s) + (r', s') = (r + r', s + s')$\\
    $(r, s)(r', s') = (rr', ss')$
\end{defn}

\begin{defn}
    For rings $R, S$ a function $\phi: R\to S$ is a homomorphism if $\forall a, b \in R$, $\phi(a + b) = \phi(a) + \phi(b)$ and $\phi(ab) = \phi(a)\phi(b)$. An isomorphism is a bijective homomorphism.
\end{defn}

\section{Fermat's and Euler's Theorems}
\begin{defn}
    Define $R$ as a ring with unit 1. $a \in R$ is called a unit if $ab = ba = 1$ for some $b \in R$. 
\end{defn}

For example, take $R = Mat_n(R)$. $R$'s unity is the identity matrix $Id$. \\ $A \in R$ is a unit $\iff AB = BA = Id$ for some $B\in Mat_n(R)$ \\ $\iff A$ is an invertible matrix \\ $\iff \det A \neq 0$


If $R = \Z_p$, $p$ prime, $x \in \Z_p$ is a unit $\iff x \neq 0$ 

\begin{exer}[HW] 
    $R^* = \{ a \in R | a $ is a unit $\}$. $R^*$ is a group w/ respect to multiplication
\end{exer}  

For example, $\Z_p^*$ is a group of order $p-1$. In every finite group $G$, the order of every element divides the order of the group (Lagrange Corollary)\\
$a^n = 1$ if $n= order(G)$


\begin{cor}[Fermat's Little Theorem] 
    $x\in \Z_p^* \implies x^{p-1} = 1 \in \Z_p^*$. 
\end{cor}
Equivalently, $x\in \Z, \gcd(x, p) = 1 \implies x^{p-1} \equiv 1 \pmod{p}$.


Equivalently, $x\in \Z \implies x^p \equiv x\pmod{p}$.
If $\gcd(p, x) = 1$, multiply both sides of the result of Fermat's Little Theorem by $p$. Otherwise, $\gcd(p, x) > 1$, $x \nmid p$ since $p$ prime, so $p | x \implies x \equiv 0 \pmod{p}$, therefore $x^p \equiv 0 \equiv x\pmod{p}$.

\begin{exm}
    Show that $n^{33} - n$ always divisible by 15 for all $n$.
\end{exm}

We want to show that $n^{33} - n$ is divisible by both 3 and 5 individually, which will then imply it is divisible by 15.


If $3 | n$, then $n^{33} - n$ is trivially divisible by $n$. Else, $\gcd(n, 3) = 1$ since 3 is prime, so by FLT, 
\begin{align*}
    n^2 &\equiv 1 \pmod{3}\\
    (n^2)^{16} &\equiv 1^{16} \pmod{3}\\
    n^{32} &\equiv 1 \pmod{3}\\
    n^{33} &\equiv n \pmod{3}\\
    n^{33} - n &\equiv 0 \pmod{3}\\
\end{align*}

The proof is same for 5: if $5 | n$, then it is trivial, else we apply FLT to say that $n^4 \equiv 1 \pmod{5}$, raise both sides to the 8th power, multiply by $n$, and substract by $n$. 
\begin{exm}
    For $R = \Z_n$, $x\in \Z_n$ is a unit $\iff \gcd(x, n) = 1$. 
\end{exm}
%Todo: Justify me :D

\begin{defn}
    The order of $\Z_n^*$ is $\phi(n)$.
\end{defn}

Here, $\phi(n)$ is the Euler totient function, or the number of integers up to $n$ that are coprime to $n$. This goes with the preceeding example, since this will count exactly the number of elements $\in \Z_n$ such that $\gcd(x, n) = 1$, which are therefore exactly the number of units. 

For $p$ prime, $\phi(p) = p - 1$, since no $d \in \{1, 2, \ldots p-1\}$ may divide $p$, since $p$ is prime. $\phi(p^k) = p^k - p^{k-1}$ since the elements that are not coprime to $p^k$ are $\{p, 2p,\ldots,p^{k-1}p\}$. There are $p^{k-1}$ such values, so the remaining $p^k - p^{k-1}$ values are coprime to $p^k$.


\begin{thm}
    $n = rs$, $r, s$ coprime, $\mathbb{Z} \cong \Z_r \times \Z_s$ (as rings). Implies Chinese Remainder Theorem
\end{thm}
%Todo: argue me :D

\begin{thm}
    $R$ and $S$ are rings with unity 1 $\implies (R\times S)^* \cong R^* \times S^*$
\end{thm}

$(a, b) \in R\times S$ is a unit $\iff (a, b) * (c, d) = (c, d) * (a, b) = (1, 1)$ unity in $R\times S$ for some ($c, d)$ \\
$\iff ac = ca = 1$ and $bd = db = 1$ \\
$\iff a\in R^*$ and $b \in S^*$\\
$\iff (a, b) \in R^* \times S^*$

\begin{cor}
    $r, s$ coprime, $n = rs \implies \Z_n^* \cong \Z_r^* \times \Z_s^*$
\end{cor}
%Todo: argue me :D

\begin{cor}
    $r, s$ coprime $\phi(n) = \phi(r)\phi(s)$ (multiplicative function)
\end{cor}

If $r, s$ are coprime, then the multiples of $r$ and the multiples of $s$ cannot intersect until $rs$. Therefore, the numbers coprime to $rs$ will be products of numbers $1 \leq x \leq r$ coprime to $r$ and $1 \leq y \leq s$ coprime to $s$, and we can use a combinatorial argument to say that there are $\phi(r)\phi(s)$ such pairs. 
\begin{cor}
    Write $n = p_1^{k_1} \cdots p_r^{k_r}$. Then $\phi(n) = \phi(p_1^{k_1}) \cdots \phi(p_r^{k_r}) = (p_1^{k_1} - p^{k_1 - 1})\cdots (p_r^{k_r} - p_r^{k_r - 1})$
\end{cor}

This is simply leveraging the preceeding Corollary that $\phi(n)$ is multiplicative, and pairwise breaking up $n$ into seperate $\phi(p_i^{k_i})$ terms. 

\begin{cor}[Euler's Theorem]
    $x\in \Z_n^* \implies x^{\phi(n)} = 1 \in Z$
\end{cor}

Recall that  $\phi(n)$ is the order of $\Z_n^*$. For $A = order(x)$, by Corollary to Lagrange, $ o| \phi(n)$, so $\exists n : An = \phi(n)$, and $n^{\phi(n)} = n^{An} = (n^A)^n = 1^n = 1 \in \Z_n^*$.

\begin{thm}
    $\Z_p^*$ is a cyclic group
\end{thm}

The proof will come later. %Todo
For now, we can use this to say $Z_p^*$ has a generator or that $Z_7^*$ has a generator

\begin{exm}
    Determine existence of solutions for, and determine solutions of an equation (congruence) $ax = b \in \Z_n$.
\end{exm}
MAGMA: Solution(a, b, n) returns sequence of solutions if they exist, and -1 if no solution.

To determine $d := \gcd(a, n)$, $ax \equiv b\pmod{n} \implies d | b$. In other words, $ax + ny = b \implies ax + ny \equiv 0 \equiv b \pmod{d}$.


If $d \nmid b$ then there are no solutions. Else, $a = a'd, b = b'd, n = n'd$. $ax \equiv b \pmod{n}$, so $a'd \equiv b'd \pmod{n'd}$. Divide the equivalent Diophantine equation by $d$ to obtain $a'x \equiv b' \pmod{n'}$. $\gcd(a', n') = 1$ (else $d < \gcd(a, n)$) so $a$ is invertible in $Z_{n'}$. $1 \equiv a'c'$ in $\mathbb{Z_{n'}}$


Multiply both sides of $a'x \equiv b' \pmod{n'}$ by $c'$ to get $a'c'x \equiv x \equiv b'c' \pmod{n'}$. This allows us to conclude that $x$ is unique modulo $n'$, but not necessarily unique modulo $n = n'd$. Solutions modulo $n: x, x + n', x + 2n' \ldots, x + (d-1)n'$. Therefore, the congruence will either have there are either 0 or $d$ solutions.

\section{Field of Fractions}
$\Z \subset \Q$. $\Z$ is an integral domain, $\Q$ is a field. There is a little bit more than an integral domain being imbedded in a field, since $\Z$ is also imbedded in $\R$ and $\C$. 

\begin{rmk}
    $\forall q\in \Q$ can be written as $\dfrac{n}{m}, n, m \in \Z$
\end{rmk}
We can call this "the most economical field including $\Z$.

\begin{thm}
    Let $R$ be an integral domain. Then there exists a field $K$, called is the field of fractions of $R$, such that 
    \begin{enumerate}
        \item $R$ contained in $K$
        \item $\forall x\in K$ can be written as $x = \dfrac{r}{s}, r , s\in R$
    \end{enumerate}
\end{thm}
Understand $R$ in terms of it's field of fractions. 

Might be easier to solve Diophantine equations in terms of rationals, then make sense of integral solution.

To prove, we need to 
\begin{enumerate}
    \item Construct $K$ 
    \item Check that all conditions in the theorem are satisfied
\end{enumerate}

Let $S$ be the set of pairs $(r, s), r, s \in R, s\neq 0$

Define an equivalence relation on $S$: $(r, s) \sim (r', s')$ if $rs' = r's$

Define $K$ as set of equivalence classes of pairs $(r, s)$

Check conditions of equivalence relation $\sim$: \\
$(r, s) \sim (r, s)$ since $rs = rs$\\
$(r, s) \sim (r' s') \iff (r', s') \sim (r, s)$ givens $rs' = r's$ and $r's = rs'$, which are obviously the same\\
$(r, s) \sim (r', s')$ and $(r', s') \sim (r'', s'') \stackrel{?}{\implies} (r, s) \sim (r'', s'')$
%todo: multiplications (commutativity from integral domain?)

$R$ integral domain $\implies$ cancelation law
%todo: why?

Define $L$ as the set of equivalence classes of pairs $(r, s)$

Let's define a fraction $\dfrac{r}{s}$ as the equivalence class of that contains a pair $(r, s)$

Define binary operations on $K$
\begin{itemize}
    \item $\dfrac{rs' + r's}{ss'}$
    \item $\dfrac{r}{s}\cdot \dfrac{r'}{s'} = \dfrac{rr'}{ss'}$
\end{itemize}
Need to check that these operations do not depend on which element of the equivalence classes that we select. 
%todo

Need to check that $K$ satsifies ring axioms\\
check field axioms

Need to imbedd $R$

Every element of $K$ is written as a $rs^{-1}$, with $r,s \in R$

Check distributivity, find what are 0 and 1 in K, check field unit axiom, Embed into into using i(r) := r/1

\section{Polynomial Rings}
\begin{defn}
    $R$ is a ring, then $R[X] = \{$polynomials in $X$ with coefficients in $R\}$\\
    = $\{a_0 + a_1x + a_2x^2 + \ldots | a_i \in R$, finitely many nonzero $a_i\}$
\end{defn}

Every $f\in R[X]$ determines a function $R\to R$, $r \to f(r) = a_0 + a_1r + a_2r^2 + \ldots$

\begin{rmk}
    In algebra, two different polynomials can define the same function with coefficients in an arbitrary ring.
\end{rmk}

$x^p, x \in \Z_p[X]$, $p$ prime. different polynomials, but the functions are the same $\Z_p \to \Z_p$ beacuse $r^p = r$ because $\forall r \in \Z_p$ by FLT

Suppose $R \subset S$ (subring). $f(x) \in R[X]$. We can also view $f$ as an element of $S[X] \implies $ we can evaluate $f(s), s\in S$. Therefore, we have to be careful to specify what ring we're working with for coefficients.

\begin{defn}
    $f(x) \in R[X]$. $r \in R$ is called a zero of $f(x)$ if $f(r) = 0$. Alternatively called a root.
\end{defn}

$x^2 + 1$ has no roots in $\R[X]$, but has two roots in $\C[X]$, $\pm i$

$x^2 - 2 = 0$ has no solution in $\Q[X]$, but has two roots in $\R[X]$

\begin{defn}[Rational Zeros Theorem]
    $f(x) = a_0 + a_1x + \ldots + a_nx^n \in \Z[X]$. If $f(\dfrac{p}{q}) = 0$, $\gcd(p, q) = 1$, then $p | a_0$ and $q | a_n$.
\end{defn}

\begin{lem}
    $R[X]$ is a ring
\end{lem}
$(a_0 + a_1x + \ldots) + (b_ + b_1x + \ldots) = (a_0 + b_0) + (a_1 + b_1)x + \ldots$\\
$(R, +)$ is an abelian group $\implies (R[X], +)$ is an abelian group\\
$(a_0 + a_1x + \ldots)(b_ + b_1x + \ldots) = (a_0 + b_0) = (\sum\limits_{i \geq 0} a_i x^i)(\sum\limits_{j \geq 0}b_jx^j) = \sum\limits_{i, j} = a_ib_jx^{ij}$

\begin{rmk}
    Fix $r \in R$. $R[X] \to R$ evalutation map, $f(x) \to f(r)$, is not always a homomorphism unless the ring is commutative
\end{rmk}
$f(x) \to f(r), g(x) \to g(r), f + g \to f(r) + g(r)$ okay since $+$ abelian, but $fg \to f(r)g(r)$ may not work if we don't know commutativity holds.
$(a_0 + a_1r +\ldots)(b_0 + b_1x + \ldots) \iff (a_0 + a_1x + \ldots)(b_0 + b_1r + \ldots)$ with $r$ placed in for $X$ after multiplying polynomials, $a_1rb_1r \neq a_1b_1r^2$ unless $R$ is a commutative ring.

\begin{defn}
    A factorization of $f(x) \in R[X]$ is $f(x) = p_1(x) \cdots p_k(x), p_i \in R[X]$. Suppose $R$ is commutative $\implies p_i(r) = 0$ for some i $\implies f(r) = 0$ (b.c $fr) = p_1(r) \cdots p_k(r)$.

    If $R$ is an integral domain $\implies$ if $f(r) = 0 \implies p_i(r) = 0$ for some $i$
\end{defn}

\begin{rmk}
    Fields are the easiest rings. The next "easiest" ring is $F[X]$, where $F$ is a field
\end{rmk}

\begin{defn}[Long Division of Polynomials]
    $F$ field, $f, g\in R[X], g\neq 0 \implies$ we can write $f = qg + r$, where $\deg(r) < \deg(g)$ or $r = 0$.
\end{defn}

$\Z_5[X]$ 

\section{Group Work 2}
\begin{rmk}
    If $\phi_p(x)$ has a root in $\Z_q$, then $\phi_p(x)$ factors as a product of linear factors.
\end{rmk}

$x^p-1 = (x-1) \phi_p(x) \implies \phi_p(x)$ has root 1 or has root $\alpha \in \Z_q, \alpha\neq 1$.

If $\phi_p(1) = 1 + 1 + \ldots + 1 = p = 0 \pmod{q}$, then $p = q$. $x^p - 1 \in \Z_p[x] = (x-1)^p \implies \phi_p(x) = (x-1)^{p-1}$

$\phi_p(x)$ has root $\alpha \neq 1 \in \Z_q$. $\alpha^p = 1 \in \Z_q$. $\Z_q^*$ is a cyclic group of order $q-1$. $<\alpha> \subset \Z_q^*$, which has $p$ elements, so $p | q-1$. Has $\alpha, \alpha^2, \ldots, \alpha^{p-1}$, all of which have order $p$ by Corollary to Lagrange. So there are all roots of $x^p - 1 \implies$ they are all roots of $\phi_p(x) \implies \phi_p(x)$ factors as $(x-\alpha)(x-\alpha^2)\cdots (a-\alpha^{p-1})$, which is a product of linear factors.

Start with $f(x) + x^d + \ldots \in \Z[x]$. Asusme $f(x)$ is irreducible $/\Q$. 
\begin{thm*}[Chebotarev density Theorem]
    Every type of the factorization is possible  over some $\Z_p$. This happens infinitely often.\\
    $\lim\limits_{N\to \infty}\dfrac{\text{\# of all primes }\leq N \text{ with a specific factorization type}}{\text{\# all primes }\leq N}$
\end{thm*}

Irreducible polynomial $x^d + \ldots \in \Q[x] \to $ Galois group $\subset S_d$. Density of primes that give a complete factorization of $f(x)$ into linear factors$ = \dfrac{1}{|\text{Galois group}|}$.

$G\subset S_5$ $|G|$ divides $|S_5| = 120$. $\dfrac{1}{|G|} \sim \dfrac{2}{95}\sim \dfrac{1}{47}$.

$x^5 + 2z + 2 \to \dfrac{9}{1040} \sim \dfrac{1}{115} \sim \dfrac{1}{120}\implies G = S_5$

\section{Homomorphisms, Ideals, and Quotient Rings}
\subsection{Homomorphisms}
\begin{defn}
    $\phi: R \to S$ is a homomorphism of rings iff \begin{itemize}
        \item $\phi$ is a homomorphism of abelian groups with respect to addition: $\phi(a + b) + \phi(a) + \phi(b)$
        \item $\phi(ab) = \phi(a)\phi(b)$
    \end{itemize}
\end{defn}

\begin{defn}
    All the set of all elements $r\in R$ such that $\phi(r) = 0$ is called the \textbf{kernel}, which will be an abelian subgroup of the ring $R$.
\end{defn}

Take $r\in R$, $s\in \Ker\phi$. Then $\phi(rs) = \phi(r)\phi(s) = \phi(r)0 = 0 = 0\phi(r) = \phi(s)\phi(r) = \phi(sr)$, so $rs, sr \in \Ker\phi$.

\subsection{Ideals}
\begin{defn}
    A subset $I \subset R$ is called an \textbf{ideal} if \begin{itemize}
        \item $I$ is an abelian subgroup with respect to addition
        \item If $r\in R$ and $s\in R \implies rs, sr \in I$.
    \end{itemize}
\end{defn}

\begin{cor}
    For any homomorphism $\phi: R\to S$, $\Ker\phi$ is an ideal
\end{cor}

\begin{exm*}
    The abelian subgroups of $\Z$ are $n\Z$. If you take $r \in \Z$ and $s \in n\Z$, then $s = nk$, and $rs = rnk = n(rk) \in n\Z$.
\end{exm*}

\begin{cor}
    All ideals in $\Z$ are of the form $I = n\Z$.
\end{cor}

$n\Z$ is the kernel of the homomorphisms $\phi: \Z \to \Z_n$ where $\phi$ maps $m \to m\pmod{n}$

\begin{exm*}
    $R_1 \times \{0\}= R_1 \times R_2$ is an ideal as well. $(s, 0)\cdot (r_1, r_2) = (sr_1, 0)$, and $(r_1, r_2)\cdot (s, 0) = (r_1s, 0)$. This is the kernel of $\phi: R_1 \times R_2 \to R_2$, where $\phi$ maps $(r_1, r_2) \to r_2$. 
\end{exm*}

Let $R$ be any ring. Then $R$ always has at least two ideals: $R$ (improper ideal) and $\{0\}$ (trivial ideal).

\begin{rmk}
    Every ideal of a field $F$ is either $F$ or $\{0\}$.
\end{rmk}
Let $I \subset F$ be an ideal. If $I = \{0\}$, we're done. Suppose $I \neq \{0\}$. Then exists $x\in I$. So $x^{-1} \in F \implies x^{-1}x = 1 \in I$. Then take any $y \in F, y \cdot 1 = y \in I$. Therefore $F = I$.

\begin{cor}
    $I \subset R$ is an ideal in a ring with unity. $u\in I$ is a unit $\implies I = R$.
\end{cor}

\begin{exm*}
    $R = R[x]$, $F$ is a field. $I = \{f \in R: f(1) = 0\}$. This is an ideal, because $f\in F$ and $g\in I$, then $f(1)g(1) = f(1)0 = 0 \in I$. Alternatively, $\phi: F[X] \to F$ where $\phi(f(x)) \to f(1)$.
\end{exm*}
$f(x) \in I \iff f(1) = 0 \iff f(x) = (x-1)g(x) \implies I = \{r(x) : f(x) = (x-1)g(x)\} = (x-1)F[x]$. This looks a \emph{lot} like $n\Z$. 

\begin{defn}
    $R$ is a ring. Pick $r \in R$. Then the ideal $I = rR := \{rs: s \in R\}$ is called a \textbf{principle ideal}.
\end{defn}

$I$ is an abelian group since $rs + rs' = r(s + s') \in I$.

Closure since $rsr' = r'rs = r(r's) \in I$

\begin{defn}
    An integral domain is called a \textbf{principle ideal domain} (PID) if every ideal is principle.
\end{defn}
Very good example here being $\Z$, where all ideals are $I = n\Z$.

Take $F$ to be a field. Two ideals: $\{0\}$ (0$\cdot F$) and $F$ (1$\cdot F$), therefore both are principle.

\begin{thm}
    $R = F[x]$ is a PID for every field $F$.
\end{thm}
Take an ideal $I \subset R$. If $I = \{0\}$, then trivial. 

Suppose $I\neq \{0\}$. What is the possible generator of $I$? Choose polynomial $f(x) \in I$ of the smallest possible degree.

\textbf{Claim}: Every $g(x) \in I$ is a multiple of $f(x) \implies I = f(x)R[x]$ principle ideal.

$g(x) = f(x)q(x) + r(x)$. Either $r(x) = 0$, and we are done, or $deg(r) < deg(f)$. Then $r(x)$ can be written as $g(x) - f(x)q(x) \implies r(x)$ is in the ideal, but this contradicts $r(x)$ having smaller degree than $f(x)$, which is a contradiction. Therefore, $deg(r) = 0 \implies g(x) = f(x)q(x)$.

\begin{rmk}
    $\phi$ is one to one $\iff \Ker\phi = \{0\}$
\end{rmk}
Because this is true for homomorphisms of abelian groups.

\begin{defn}
    For ring $R$ and ideal $I \subset R$ such that $I \neq R$, $I$ is called \textbf{maximal} if every ideal $J$ such that $I \subset J \subset R$ is either $I$ or $R$.
\end{defn}

\begin{exm*}
    $\{0\} \subset F$ field, $p\Z \subset \Z$ where $p$ prime.\\
    $F[x]$, for $F$ field, is a principle ideal domain. Take $f(x)F[x] \subset F[x]$, where $f(x)$ is an irreducible polynomial $\implies f(x)F[x]$ is a maximal ideal
\end{exm*}

\begin{exm}
    Compute $\Z_2[x]/(x^2 + x + 1)F[x]$. 
\end{exm}
What are the cosets? Take $g(x) \in \Z_2[x]$ and take its coset $g(x) + x^2 + x + 1$.

Claim: there are only four cosets. The ideal itself $I$, $1 + I$, $x + I$, $(1 + x) + I$

Take any coset $g(x) + I$. Perform long division $g(x) = (x^2 + x + 1)q(x) + r(x)$, where $deg(r) < 2$. All possible $r(x)$ are 0, 1, $x$, $x + 1$.

\section{Unique Factorization Domains}
Define $R$ to be an integral domain. 
\begin{defn}
    For $p \in R$ irreducible, if $p = ab \implies a$ or $b$ is a unit
\end{defn}

\begin{defn}
    If $(p) \subset R$ is a prime ideal, then $p\in R$ prime.
\end{defn}
Recall Euclid's Lemma: $p | ab \implies p | a$ or $p | b$ $\forall a, b \in R$

\begin{rmk}
    If $p$ is prime then $p$ is irreducible
\end{rmk}

\begin{defn}
    An integral domain $R$ is called a unique factorization domain (UFD) if\\
    1) Every element can be written as $r = up_1p_2\cdots p_r$ where $u$ is a unit and $p_i$ are irreducible elements\\
    2) Suppose $up_1\cdots p_r = vq_1 \cdots q_s$, with $u, v$ unit, everything else irreducible, then $r = s$ and after reordering $q_1\ldots q_s$, $p_i = q_i \cdot u)i$ for some unit $u_i$
\end{defn}

\begin{rmk}
    If $R$ is a UFD, then every irreducible element is prime
\end{rmk}
$r \in R$ irreducible. Suppose $r | ab$, then $ab = pc, c\in R$. Apply factorization to $a, b, c$: $(u p_1\ldots p_r)(vq_1\ldots q_s) = p(wl_1 \ldots l_k)$, $u, v, w$ are units

Uniqueness of factorization $\implies p_i = \alpha p$ or $q_i = \alpha p$ for for some $i$, unit $\alpha$. 

In the first case, then $a = up_1 \ldots p_{i-1}(\alpha p)p_{i + 1}\ldots p_r \implies p | a$

\begin{rmk} %Todo: is this a Euclidean domain
    Suppose $R$ is an an integral domain where factorization exists. $\implies$ one can conclude that, if every irreducible unit is prime, then $R$ is a UFD
\end{rmk}
Suppose $up_1\cdots p_r = vq_1 \cdots q_s$, with $u, v$ unit. Then $p_1 | vq_1\ldots q_s$. $p_1 \nmid u \implies p_1 | q_i$ for some $i$. (Because $p_1$ is irreducible, and here all irreducibles are prime). By rearranging, $p_1 | q_1$, so $p_1 \beta = q_1$. $q_1$ irreducible implies $\beta$ must be a unit. Cancel $p_1$ using integral domain cancelation law: $up_2\ldots p_r = (v\beta)q_2\ldots q_s$. By induction, we are done.

\begin{exm*}
    $K[X]$ is a UFD if $K$ is a field.
\end{exm*}
(1) $f(x) \in K[x]$ is irreducible. We already checked that $f(x)K[x]$ is maximal. But every maximal ideal is prime $\implies f(x)$ is a prime element.

(2) Show existence of factorization: take polynomial $f(x) \in K[x]$. Argue by induction on $deg(f(x))$. If $f(x)$ is unit $\iff deg(f(x)) = 0$ $\implies$ factorization exists. If $f(x)$ is irreducible $\implies$ factorization exists. Else, $f(x) = g(x)h(x)$ for $0 < deg(g(x)), deg(h(x)) < deg(f(x))$. Both admit factorizations by induction, so combine then to get factorization.

Suppose $r = r_1$ does not allow factorization $\implies r_1$ is not a unit, not irreducible $\implies r = ab$, where $a, b$ not units. One of them, say $a = r_2$ does not allow factorization. $r_1 = r_2b_2$, $b_2$ is not a unit. Can continue inducting, and get a sequence $r_i = r_{i+1}b_{i+1}$ where all $r_1, r_2, \ldots$ do not allow factorization and $b_1, b_2, \ldots$ are not units. 

Take $(r_1)$ and $(r_2)$. $(r_1) \subset (r_2) \subset (r_3) \subset \ldots$. Can it be that $(r_1) = (r_{i +1})$? No. Then $r_i = r_{i +1}b_{i + 1}$ and $r_{i + 1} = r_ic_i \implies r_i = r_ib_{i + 1}c_i \implies 1 = b_{i+1}c_i \implies b_{i +1}$ is a unit, contradiction.

$(r_1) \subsetneq (r_2) \subsetneq (r_3) \subsetneq \ldots$

\begin{defn}
    A commutative ring $R$ is called Noetherian if there are no infinite ascending chains of ideals $I_1 \subsetneq I_2 \subsetneq I_3 \subsetneq \ldots$
\end{defn}

\begin{cor}
    If $R$ is Noetherian integral domain where irreducible elements are prime, then it's a UFD
\end{cor}

\section{Field Extensions}
$K \subset F$, towers of fields: $K_1 \subset K_2 \subset K_3$

$K$ field, $f(x) \in K[x]$ irreducible polynomial. Take $I = f(x)$ maximal ideal. $F = K[X]/I$ is a field.
\begin{thm}
    $K \to K[x] \to K[x]/I = F \implies K \to F$ by composition. $f(x)$ has a root $\alpha \in F$
\end{thm}

\begin{cor}
    If you take any polynomial in $f(x) \in K[x]$, factors into linear factors in some field extension of $K \subset F$
\end{cor}

\textbf{Proof}: $K \stackrel{\phi}{\to} F$. Ker$\phi$ is an ideal of $K$, $K$ is a field, either Ker$\phi = \{0\}$ (and $\phi$ is injective) or Ker$\phi = K$. But that can't happen because $1 \in K \to 1 \in K[x] \to 1 + I$, a unity in $F$, which is certainly not zero, so $\phi(1) \neq 0$, and $I$ must be $\{0\} \implies K \to F$

Claim: $x + I = \alpha \in F$ is going to be a root of $f(x)$ $f(x + I) = f(x) + I = I = 0 \in F$. If confused, try plugging in $x + I$ and doing it out.

$x^2 + 1 \in \R[x]$, $I = (x^2 + 1)$. $\R[x]I = \{p(x) + I\} = \{p(x) = I : deg(p < 2)\}$. Indeed $p(x) = (x^2 + 1)q(x) + r(x) \implies p(x) + I = r(x) + I$ because $p(x) - r(x) = q(x)(x^2 + 1) \in I$. Morever, every coset can be written uniquely as $\{a + bx + I\}$ where $a, b \in \R$. 

\begin{defn}
    Let $K \subset K$ be a field extension. Choose some $\alpha \in F$. $\alpha$ is \textbf{algebraic} over $K$ if there exists $f(x) \in K[x]$ such that $f(\alpha) = 0$.
\end{defn}

\begin{defn}
    Any element that is not algebraic is \textbf{transcendental} over $K$
\end{defn}

\begin{exm*}
    Consider $\Q \subset \C$. Algebraic $\alpha \in \C$ over $\Q$ are called algebraic (transcendental) numbers.
\end{exm*}

\begin{thm}
    $e, \pi$ are transcendental over $\Q$ 
\end{thm}
Very hard to prove. Much easier to prove numbers are algebraic

\begin{rmk}
    If you have a trivial field extension $F \subset F$, then all elements will be algebraic    
\end{rmk}
In a real analysis context, algebraic and transcendental are with rational coefficients, so $\pi$ and $e$ are transcendental. For the extension $\R \subset \R$ and $\R \subset \C$ both are now algebraic, since $x - \pi = 0$ has $\pi$ as a solution, and $x - e = 0$ has $e$ as a solution.

\begin{lem}
    Suppose $K \subset F$ field extension. Take $\alpha \in F$ algebraic $\implies$ there exists a unique minimal (aka irreducible) polynomial irr($\alpha$, $K$) which is \\
    1) irreducible and nonzero \\
    2) has $\alpha$ as a root \\
    3) and monic 
\end{lem}
$irr(\alpha, K)$ is the minimal polynomial of $\alpha$ over $K$.

The main tool to prove this is the evalutation homomorphism. $\phi: K[x] \to F$ which sends $f(x) \to f(\alpha)$.

$I = \Ker(\phi) \subset K[x]$ ideal. By definition, it is $= \{ f\in K[x] : f(\alpha) = 0\}$. $I \neq 0 \iff \alpha$ is algebraic /$K$, and $I = 0 \iff \alpha$ is transcendental /$K$.

\textbf{Case 1}: $I \neq 0 \iff \alpha$ is algebraic.
The ideal I is principle: $I = (f)$. Rescale $f$ by a constant to make it monic. Why is it irreducible? If $f(x) = a(x)b(x)$ with $deg (a), deg(b) < deg(f)$. $f(\alpha) = a(\alpha)b(\alpha) = 0$, but then at least one of them has to be in the ideal, but they can't be since they have degree less than $f$ (because we selected $f$ to be the generating polynomial). Therefore $irr(\alpha, K)$ exists.

Why is it unique? Suppose $g(x)$ also satisfies the three conditions. Therefore, $g(\alpha) = 0$, so $g(x)$ is in the ideal $I = (f)$. But then $g(x) = f(x)q(x)$. But $g(x)$ is irreducible, so $q(x)$ has to be a constant, else $g(x)$ has a nontrivial factorization, and must be 1 else one of $f(x)$ or $g(x)$ isn't monic.

\begin{exm*}
    $irr(\sqrt{2}, \Q) = x^2 - 2$, $irr(\sqrt{2}, \R) = x - \sqrt2$.
\end{exm*}

\begin{defn}
    Suppose $K \subset F$ fields, $\alpha \in F$. A \textbf{simple field extension} $K(\alpha)$ is the smallest subfield of F that contains $K$ and $\alpha$. Generalization: $K(\alpha, \beta)$ contains $K$, $\alpha$, and $\beta$.
\end{defn}

$\phi : K[x] \to F$, $I = \Ker\phi$. $I \neq 0 \iff \alpha$ algebraic/$K$\\
$\implies I = (f)$, where $f = irr(\alpha, K)$

Apply the first isomorphism theorem:

\begin{tikzcd}
    K[x] \arrow[r, "\phi"] \arrow[d]
    & F \\
    K[x]/I  \arrow[r, "\simeq"]
    & Im\phi \arrow[u, "\cup"]\\
\end{tikzcd}

$\implies Im\phi$ is a subfield, isomorphic to $K[x]/I$, contains $J$, $\alpha = \phi(x)$. 

\textbf{Claim}: $Im(\phi) = K(\alpha)$. Why is it the smallest?
Suppose $N$ is a subfield of $F$ that contains $K$ and $\alpha$. Is $Im(\phi) \in N$? Yes, $\phi(a_0 + \ldots + a_nx^n) = a_0 + \ldots a_na^n \in N$

\textbf{Case 2}: $\phi: K[x] \to F$ which sends $p(x) \to p(\alpha)$. $I = \Ker\phi = 0 \implies \phi$ is injective. 

$K[x] \stackrel{\phi}{\to} F \implies K(x) = \{ \dfrac{p(x)}{q(x)}: p, q \in K[x]\}$ is also contained in $F \implies K(\alpha) \cong K[x]$

\section{Linear algebra over a field K}
Vector space of column vectors $\begin{bmatrix}
    a_1\\
    \vdots\\
    a_n
\end{bmatrix}$, $a_i \in K$

Two operations: $\begin{bmatrix}
    a_1\\
    \vdots\\
    a_n
\end{bmatrix} + \begin{bmatrix}
    b_1\\
    \vdots\\
    b_n
\end{bmatrix} = \begin{bmatrix}
    a_1+b_1\\
    \vdots\\
    a_n+b_n
\end{bmatrix}$\\
and $k \begin{bmatrix}
    a_1\\
    \vdots\\
    a_n
\end{bmatrix} = \begin{bmatrix}
    ka_1\\
    \vdots\\
    ka_n
\end{bmatrix}$

These operations satisfy axioms of vector space /$K$. 

Set $V$ with 2 operations: \\
$V\times V \to V$, sends $u, v \to u + v$, and $K \times V \to V$ sending $k, v \to ku$ subject to axioms:
\begin{itemize}
    \item $(V, +)$ is an abelian group, in particular we have a zero vector $0 \in V$
    \item distributivity $k(u + v) = ku + kv$ and $(k + k')u = ku + k'u$
    \item "action" or "associativity" $l(ku) = (lk)u$, and $1 \cdot v = v$
\end{itemize}

\begin{exm*}
    Suppose we have a field extension $K \subset F$. Then we have $f_1 + f_2$, $f_1, f_2 \in F$, and can compute $kf$, for $k \in K$ and $f\in F$. Therefore, as a consequence of ring axioms, $F$ satisfies the axioms of a vector space over a field $K$. 
\end{exm*}

\begin{exm*}
    $R \subset C$
\end{exm*}
View $\C$ as a vector space over $\R$, with basis vectors $1$ and $i$.

\begin{rmk}
    We can imbed field $K$ into a ring $R$ and this still holds since we used ring axioms only.
\end{rmk}

\begin{defn}
    Suppose we have $V$ vector space/$K$, with $v_1, \ldots, v_k \in V$. We say $v_1, \ldots, v_k$ \textbf{span} $V$ if $\forall v \in V$ can be written $v = \sum a_iv_i$ for $a_i \in K$.
\end{defn}

\begin{defn}
    $v_1, \ldots v_k$ are \textbf{linearly independent} if $\sum a_1 v_1 = 0 \implies \forall a_i = 0$.
\end{defn}

\begin{defn}
    $\{v_1, \ldots, v_k\}$ is a \textbf{basis} if they span and are linearly independent.
\end{defn}

\begin{lem}
    $v_1, \ldots, v_n$ span $V$ and $u_1, \ldots, u_k$ are linearly independent, then $k \leq n$.
\end{lem}
$u_i = \sum\limits_{j = 1}^n a_{ij}v_j$. Argue by contradiction. Suppose $k > n$. Leters try to find a nontrivial linear combination (all terms nonzero) $x_1u_1 + \ldots x_ku_k = 0$ $x_i \in K$.\\
$\implies \sum\limits_{i=1}^k x_iu_i = 0$\\
$\implies \sum\limits_{i=1}^k x_i\sum\limits_{j = 1}^n a_{ij}v_j = 0$\\
$\implies \sum\limits_{i=1}^k\sum\limits_{j = 1}^n x_ia_{ij}v_j = 0$\\
Certainly true if $\sum\limits_{i = 1}^k x_ia_{ij} = 0$ $\forall j = 1,\ldots, n$. We have a system of $n$ homogeneous linear equations in $k$ variables $x_1, \ldots, x_k$, and $k > n$. Therefore, it has a nontrivial solution.

Run row reduction, we have $> 0$ independent variables, which can take arbitrary values.
\begin{cor}
    If $V$ has a finite basis with $n$ vectors, then every other basis also has $n$ vectors. This $n$ is called the \textbf{dimension} of $V$ over $K$ (otherwise $dim V = \infty$)
\end{cor}

\begin{exm*}
    dim $\C$ over $\R$ is 2 with basis 1 and $i$
\end{exm*}
$\alpha \in \C$, $\alpha = a \cdot 1 + b \cdot i, a, b \in \R \implies 1, i$ span $\C$

$a, b\in \R, a + bi = 0\implies a = b = 0 \implies 1$ and $i$ are linearly independent. 

\begin{defn}
    $K \subset F$ a field extension $\implies F$ vector space/$K$. Then the dimension of $F$ over $K$ is called the \textbf{degree} of the field extension, notated $\left[F : K\right]$
\end{defn}

\begin{lem}
    $f(x) \in K[x]$ irreducible of degree $n$. $I = (f) \subset K[x]$, $F = K[x]/I$. Then $[F : K] = n$, easy to write a basis as well.
\end{lem}
$\alpha = X + I \in F$. Claim: 1, $\alpha, \alpha^2, \alpha^3, \ldots, \alpha^{n-1}$ is a basis of $F$ over $K$, with dimension $n$.

$F = K[x]/I \implies$ elements of $F$ are cosets $p(x) + I$, $p(x) \in K[x]$. Recall $p(x) =f(x)q(x) + r(x)$, degree of $r <$ degree $f$. $I = (f(x))$, $f(x)q(x) \in I$, $p(x) + I = r(x) + I$. 

If $r(x)$ and $r'(x)$ give the same coset, then $r(x)$ must be equal to $r'(x)$, since $r(x) - r'(x) \in I \implies r(x) - r'(x) = f(x)s(x) \implies \deg(r - r') < \deg(f) \implies r = r' \implies$ we can write every element of $F$ as $a_0 + a_1x + \ldots + a_{n-1}x^{n-1} + I, a_i \in K$ uniquely. $a_0 + a_1\alpha + \ldots + a_{n-1}\alpha^{n-1} = a_0(1 + I) + a_1(x + I) + \ldots + a_{n-1}(x + I)^{n-1} =$ above.

Therefore, $\{1, \alpha, \ldots, \alpha^{n-1}$ is a basis, since every element of $F$ is a unique linear combination of $1, \ldots, \alpha^{n-1}$ with coefficients in $K$.

\begin{cor}
    $K \subset F$ field extension, $\alpha \in F$ algebraic over $K$ with minimal polynomial of degree $n \implies[K(\alpha), K] = n$, with basis $\{1, \alpha, \ldots, \alpha^{n-1}$.
\end{cor}

$f(x) = irr(\alpha, K)$. Last time: $K(\alpha) \cong F/(f)$ with $\alpha$ matched with $x + I$.

\begin{exm*}
    $K = \Q, \alpha \in \C$, study $K(\alpha)$?
\end{exm*}
$\Q(\sqrt{2}), irr(\sqrt{2}) = x^2 - 2 \implies [Q(\sqrt{2}), \Q] = 2$, with basis 1, $\sqrt{2}$.

Therefore, $\forall x \in \Q(\sqrt{2})$ can be written uniquely as $a + b\sqrt{2}, a, b\in \Q$.

\begin{exm*}
    $\Q(\sqrt{1 + \sqrt{3}})$
\end{exm*}
$\alpha^2 = 1 + \sqrt{3} \implies \alpha^2 - 1 = \sqrt{3} \implies (\alpha^2 - 1)^2 = 3 \implies \alpha^4 - 2 \alpha^2 - 2 = 0$. Is irreducible by Eisenstein with $p = 2$.

Therefore, $[\Q(\alpha), \Q] = 4$, basis is $1, \alpha, \alpha^2, \alpha^3$

How to write $\dfrac{1}{1 + \alpha + \alpha^2}$ as linear combination?

$x_0 + x_1 \alpha + x_2 \alpha^2 + x_3 \alpha^3$, solve for $x_0,\ldots x_4$. 1 = $(1 + \alpha + \alpha^2)(x_0 + x_1 \alpha + x_2 \alpha^2 + x_3 \alpha^3)$. $\alpha^4 = 2\alpha^2 + 2$. Multiply out, and substitute in for $\alpha^4$ at each step to only use powers of $\alpha < 4$. Gives a system of 4 equations in four variables.

\section{Algebraic Extensions}

\begin{defn}
    A field extension $K \subset F$ is called \textbf{algebraic} if every element $\alpha \in F$ is algebraic/$K$.
\end{defn}

\begin{thm}
    Every finite extension is algebraic
\end{thm}

$[F : K] = n, \alpha \in F$. Basis $e_1, e_2, \ldots, e_n \in F$. Take $1, \alpha, \ldots, \alpha^n$. Are linearly dependent $\implies x_0 + x_1\alpha + \ldots + x_n\alpha^n = 0$ for some $x_i \in K$, not all 0, so $P(\alpha) = 0$.

\begin{exm*}
    $\Q(2^{a/3})$
\end{exm*}
$[\Q(2^{a/3}) : \Q] = 3$ since $x^3 - 2 = 0$, irr by Eisenstein\\
$\implies \forall p \in \Q(2^{1/3})$ is algebraic over $\Q$

Take $\beta = 1 + 2^{1/3} + 2^(2/3)$. Basis of $\Q(2^{1/3})$ is $\{1, 2^{1/3}, 2^{2/3}\}$. Compute $1, \beta, \beta^2, \beta^3$ as linear combinations of 1, $2^{1/3}, 2^{2/3} \implies$ set-up a linear combination with unknown coefficients $x_0 + x_1\beta + x_2\beta^2 + x_3\beta^3$ in terms of the basis. Solve a SLE with 4 variables and 3 equations.

\begin{rmk}
    Suppose $\alpha$ is algebraic over $F$. Then $F(\alpha) \cong F[x]/(f)$ where $f(x)$ is the irreducible polynomial.
    We have a basis of $F(\alpha)$ over $F$ given by $1, \alpha, \alpha^2, \ldots, \alpha^{n-1}$, where $n$ is the degree of $f(x) = [F(\alpha) : F]$
\end{rmk}

\begin{thm}[Transitivity of degree]
    $F \subset K \subset L$ fields. Suppose $L$ is a finite extension of $F$. Then $[L : F] = [L : K][K : F]$
\end{thm}
\textbf{Proof}: Choose a basis $\alpha_1, \ldots, \alpha_n$ of $K$ as a vector space over $F$. Choose $\beta_1, \ldots, \beta_m$ of $L$ as a vector space over $K$. Claim $\alpha_i\beta_j$ for $i = 1, \ldots, n$ and $j = 1, \ldots, m$ is a basis of $L$ over $F$.

Have to check that \\
(1) every element $\gamma \in L$ can be written as a linear combination of $\alpha_i\beta_j$ with coefficients in $F$\\
(2) These vectors are linearly independent over $F$.

Well, the $\beta$ terms being a basis of $L$ over $K$ means that $\gamma = \sum\limits_{j = 1}^m k_j \beta_j$. But the $\alpha$ terms form a basis of $K$ over $F$, so each $k_j = \sum\limits_{i = 1}^n f_{ij}\alpha_i$. Therefore, you can substitute in the summations to get $\gamma = \sum\limits_{j=1}^m \sum\limits_{i = 1}^n f_{ij}a_ib_j$. so we have part (1).

(2) Claim: $\alpha_i\beta_j$ are linearly independent over $F$.
Write $\sum_{i, j}f_{ij}\alpha_i\beta_{j} = 0$. To show linear, independence, we must show that all $f_{ij}$ are 0.

Well, this implies that $\sum\limits_{j = 1}^m (\sum\limits_{i = 1}^n f_{ij} \alpha _i)\beta_j = 0$, but the $\beta$ terms form a basis, so are linearly independent with each summation term being in $K$, so each summation w.r.t $j$ equals 0. Well, by the same logic, since $\alpha$ are all linearly independent, all $f_{ij}$ must be zero, and we are done.

\begin{cor}
    If $[L : F]$ is prime, then either $[L : K] = 1 \implies L = K$ or $[K : F] = 1 \implies K = F$
\end{cor}

\begin{exm*}
    $[\Q(2^(a/3)) : \Q] = 3$
\end{exm*}
$\beta = 1 + 2^{1/3} + 2^{2/3}$. Then, take $\Q \subset \Q(\beta) \subset \Q(\alpha)$. Then either $\Q = \Q(\beta)$ or $\Q(\beta) = \Q(2^{1/3})$. The latter must be true, since $\beta$ is not rational $\implies \deg(irr(\beta, \Q)) = [\Q(\beta): \Q] = [\Q(2^{1/3}): \Q] = 3$

\begin{exm*}
    $\Q[\sqrt{2}]$
\end{exm*}
Has degree 2, since irreducible polynomial is $x^2 - 2$. Take $\Q[\sqrt{2}, \sqrt{3}]$ over $\Q[\sqrt{2}]$ has degree two because the irreducible polynomial is $x^2 - 3$ 

Is this irreducible? Well if not, then there is a root, namely $\sqrt3$ so then $\sqrt{3} \in \Q[\sqrt{2}]$, so $\sqrt3 = a + b\sqrt2$ for $a, b \in \Q$. Square both sides, get 3 = $a^2 + 2b^2 + 2ab\sqrt{2}$, which can't be true unless $a$ is zero or $b$ is zero.

If $b$ is zero, then $\sqrt{3} = a$, but we know it's irrational. If $a$ is zero, then we have $\sqrt{3} = b\sqrt{2}$, or $2b^2 - 3 = 0$, which is irreducible by Eisenstein, so $b$ is irrational if the two sides are indeed equal. 

Therefore, $[\Q(\sqrt2, \sqrt3)]$ has degree 4, with basis $1, \sqrt{2}, \sqrt{3}, \sqrt{6}$. This is a simple field extension, since we've already checked that $x^4 - 10x^2 + 1$ is an irreducible polynommial with degree 4 with $\sqrt{2} + \sqrt{3}$ as a root. 

Therefore, we have $\Q \subset \Q(\sqrt2 + \sqrt3) \subset \Q(\sqrt2, \sqrt3)$, where the the first extension has degree 4, and the whole extension has degree 4, so the right two must be equal, and the last field must have degree 4 over $\Q$

\begin{exm*}
    $\Q(\sqrt{2}, \sqrt[3]{2})$
\end{exm*}

$F \subset K$ field extension. Consider $L = \{ \alpha \in L : \alpha$ is algebraic over $F \}$ If $F\subset K$ i algebraic $\implies L = K$. 

\begin{lem}
    $L$ is a subfield of $K$, called an \textbf{algebraic closure} of $F$ in $K$
\end{lem}

\begin{exm*}
    $\Q \subset \C$. Algebraic closure of $\Q \in \C$ is denoted $\overline{\Q}$, field of algebraic numbers
\end{exm*}
Proof of lemma: $\forall, \alpha, \beta \in L$, check that $\alpha\beta$, $\alpha - \beta$, and $\alpha/\beta$ is in $L$. Meaning, these three should also algebraic over $K$.

Consider extension $K \subset K(\alpha)$, which is finite. Then extension $K(\alpha) \subset K(\alpha, \beta)$, which is also finite since $\beta$ is algebraic over $K$. Therefore $K \subset K(\alpha, \beta)$ is also finite with degree of product of the subdegrees. Because this extension is finite, it must be algebraic $\implies \alpha \pm \beta, \alpha\beta, \alpha/\beta$ are algebraic over $K$

\begin{rmk}
    How can we find a 
\end{rmk}

\begin{exm*}
    $\overline{Q} = \{ \alpha \in \C : \alpha$ is algebraic over $\Q\}$ is an algebraic closure, and is therefore automatically a field without having to prove it specifically
\end{exm*}

\begin{defn}
    An algebraic closure $\overline{K}$ of a field $K$ is a field extension of $K$ such that \begin{enumerate}
        \item $\forall\alpha \in \overline{K}$ is algebraic over $K$
        \item $\overline{K}$ is algebraically closed, which means that every polynomial in $\overline{K}[x]$ has a root in $\overline{K}$
    \end{enumerate}
\end{defn}
(2) $\iff$ every polynomial in $\overline{K}[x]$ factors into linear factors in $\overline{K}[x]$

\begin{exm*}
    $\C$ is algebraically closed$\implies \C$ is an algebraic closure of $\R$
\end{exm*}
(1) $\C$ is algebraically closed\\
(2) $a + bi \in C$ is algebraic over $\R$? $(x - a - bi)(x - a + bi) = x^2 - 2ax + (a^2 + b^2)$

\begin{exm*}
    $\overline{\Q}$ is algebraically closed
\end{exm*}

\begin{exm*}
    $c = \sum\limits_{n \geq 1} \dfrac{1}{10^{n!}}$
\end{exm*}
Last time: $c$ is a Liouville number, which means that $c\not\in\Q$, and $\forall n \geq 1, \exists \dfrac{p}{q} \in \Q$ such that $\left| c - \dfrac{p}{q}\right| \leq \dfrac{1}{q^n}$

\begin{lem}
    Liouville numbers are transcendental $(\not\in \Q)$
\end{lem}
Argue by contradiction> Suppose that a Liouville number $\alpha$ is algebraic/$\Q$. Well, then there exists an irreducible polynomial $f(x) \in \Q[x]$ such that $f(\alpha) = 0$. Rescale the polynomial by the lcm of the denominators such that $f(x) \in \Z[x]$

$f(\alpha) = 0$, but $f(\dfrac{p}{q}) \neq 0$ because $f(x)$ is irreducible/$\Q$

$f(x) = a_0x^m + a_1 x^{m-1} + \ldots + a_m$ with $a_i \in \Z$.

$\left|f(\dfrac{p}{q})\right| = |a_0 \dfrac{p^m}{q^m} + \ldots a_m| \geq \dfrac{1}{q^m}$ because = $\left|\dfrac{a_0p^m + a_1p^{m-1}q + \ldots + a_mq_m}{q^m}\right|$

Choose $\dfrac{p}{q}$ such that $\left| \alpha - \dfrac{p}{q}\right| < \dfrac{1}{q^n}$. Then $f(\alpha) - f(\dfrac{p}{q}) = f'(x)(\alpha - \dfrac{p}{q})$ $x$ between $\alpha$ and $\dfrac{p}{q}$

$\left|f(\alpha) - f(\dfrac{p}{q})\right|  = \left|f'(x)\right|\left|\alpha - \dfrac{p}{q}\right|$ 

$|x - \alpha| \leq 1$ because $\left| \dfrac{p}{q} - \alpha\right| < \dfrac{1}{q^n} \leq 1$. Let $M$ be the $\sup\limits_{|x - \alpha| \leq 1}\left|f'(x)\right|$, so $$\dfrac{1}{q^m} \leq \left|f(\dfrac{p}{q})\right| = \left|f(\alpha) - f(\dfrac{p}{q})\right| \leq M\left| \alpha - \dfrac{p}{q}\right| \leq M\dfrac{1}{q^n}$$
$\implies \dfrac{1}{q^m} \leq \dfrac{M}{q^n} \implies q^n \leq Mq_a^m \implies 2^{n-m } \leq q^{n-m} \leq M$. This obviously can't be true for all $n$

\section{Geometric Constructions}
What can be constructed with a straightedge and a compass

Classical problems
\begin{enumerate}
    \item Doubling the cube (basically, can we construct cube root of 3)
    \item Trisect angle
    \item Squaring the circle (circle with area $A$ to square with area $A$)
\end{enumerate}

Algebraic interpretation: Let's define field $K \subset \R$ to be a field of all numbers $x$ such that the segment of length $x$ can be constructed with straightedge and compass starting with a segment of length 1.

You can take $\alpha$ and $\beta$ and get $\alpha + \beta$

Start with $1 \to \Q$. Easy.

Take $a + 1$, then half circle, then get altitude, which has length $\sqrt{a}$. Then we can adjoin $\Q$ with any square root.

Let's call $\alpha \in \R$ constructible if it can be constructed using straightedge and compass. 

\begin{thm}
    $\alpha \in \R$ is constructible $\iff$ there exists $\Q = K_0 \subset K_1 \subset K_r$ such that $K_r = K_{r-1}(\sqrt[]{\beta_r})$, where $\beta_r \in K_{r-1}$
\end{thm}
We already just proved one direction.

For the other way, we can formalize "straightedge and compass" as we can create a series of points $(x_n, y_n) \in \R^2$ with starting points $(x_1, y_1) = (0, 0)$ and $(x_2, y_2) = (1, 0)$.

What can $(x_n, y_n)$ be? Either $(x_n, y_n)$ is an intersection point of a line passing through $(x_i, y_i), (x_j, y_j)$ and a line through $(x_k, y_k)$ and $(x_l, y_l)$ for $i, j, k, l < n$, or we can use circles with center $(x_i, y_i)$ and passint through $(x_j, y_j), i, j < n$.

Claim: we can compute $(x_n, y_n)$ using $x_i, y_i$ for $i < n$ using $+, -, \cdot, /$ and $\sqrt[]{}$

$y - y_i = \dfrac{y_j - y_i}{x_j - x_i}(x - x_i)$ or $x = x_i$ if $x_i = x_j$, so a line $y = kx + b$ or vertical lines.

To intersect two lines $y = kx + b$ and $y = k'x + b'$, we just have to solve the linear system of two equations in two variables, and we can find $(x, y)$ using arithimetic operations $+, -, \cdot, /$.

From circle, have $(x - x_i)^2 + (y - y_i)^2 = R^2 = (x_j - x_i)^2 + (y_j - y_i)^2$ and compute using $+, -, \cdot$

Intersecting a line and $(x - x_i)^2 + (y - y_i)^2 = R^2$, solve for $x, y$ by substituting the linear equation in for $y$, and solving the quadratic using the quadratic formula, which requires a square root

Finally, we can intersect two circles $\begin{cases}
    (x - x_i)^2 + (y - y_i)^2 = R^2\\
    (x - x_j)^2 + (y - y_j)^2 = \overline{R}^2
\end{cases}$
If we subtract, the degree terms go away, and we are left with a linear equation in $x$ and $y$
\begin{cor}
    If $\alpha$ is constructable $\implies \alpha$ is algebraic / $\Q$, and its degree is a power of 2.
\end{cor}
\textbf{Proof}: $\alpha \in K_r$ like in theorem. Then $[K_r : Q] = [K_r:K_{r-1}][K_{r-1}:\Q] = 2[K_{r-1}:\Q] = 2^r$ by induction

On the other hand, we have $\Q \subset \Q(\alpha) \subset K_r$. So again, by transitivity, $2^r = [K_r : \Q] = [K_r: \Q(\alpha)][\Q(\alpha) : \Q]$\\
$\implies [\Q(\alpha):\Q] = 2^s$, which is the degree of the minimal polynomial of $\alpha$.

\begin{cor}
    We can't double the cube.
\end{cor}
\textbf{Proof}: well if we can, then its side, $\sqrt[3]{2}$, is constructable. Therefore, $\sqrt[3]{2}$ has degree $2^s$. But it has degree 3, since the minimal polynomial is $x^3 - 2$. Therefore, the cube can't be doubled.

\begin{cor}
    We can't trisect a general angle.
\end{cor}
$\cos(\alpha + \beta) = \cos(\alpha)\cos(\beta) -\sin(\alpha)\sin(beta)$. So $\cos(3\phi) = \cos(2\phi)\cos(\phi) - \sin(2\phi)\sin(\phi)$ =\\ $[2\cos^2(\phi)-1]\cos(\phi) - 2\sin^2(\phi)\cos(\phi) = 2\cos^3\phi - \cos\phi - 2(1 - \cos^2\phi)\cos\phi = 4\cos^3\phi - 3\cos\phi$

Claim: $\cos(60 \deg) = \dfrac{1}{2}$ is constructable, but $\cos(20\deg)$ is not. $\cos(20 \deg$) is a root of $8x^3 - 6x - 1$, which is irreducible. Therefore, the degree of $\cos(20\deg)$ is 3, which is not a power of 2.

Why irreducible? Well, degree 3, so it has to have a root, and by rational roots theorem it has none in $\{\pm1, \pm 1/2, \pm 1/4, \pm 1/8\}$, therefore it is irreducible.

\begin{cor}
    You cannot square a circle
\end{cor}
If you want to create create a square with area $\pi$, then you need to construct $\sqrt{\pi}$, which is transcendental / $\Q$. Suppose $\sqrt[]{\pi}$ is algebraic / $\Q$. Then $\sqrt[]{\pi} \sqrt[]{\pi}$ must also be algebraic, but in fact $\pi$ is transcendental (by a difficult theorem proved by Lindemann $\sim1890$)

\section{Finite Fields}
$F$ is a field $\implies F$ contains the smallest possible subfield. This field, known as a prime field, is either $\Q$ or $\Z_p = \F_p$ for prime $p$

$F$ a finite field $\implies F \supset \F_p$ for $p = char F \implies F$ is a vector space over $\F_p \implies |F| = p^n$, where $n = [F: \F_p]$

\begin{thm}
    There exists a field with $p^n$ elements $\forall$ prime $p, n \geq 1$
\end{thm}
Idea 1: prove existence of an irreducible polynomial $f(x) \in \F_p[x]$ of degree $n \implies \F_p[x]/(f) = F$ field with $p^n$ elements. Counting gets harder for $n \geq 2$

Idea 2: let $F$ be a finite field with $p^n$ elements. Then $F^* = F\setminus\{0\}$ is a group with respect to multiplcation with $p^n - 1$ elements.\\
$\implies \forall x \in F^*$, ord$(x) | p^n - 1$ (Cauchy theorem)\\
$\implies x^{p^n - 1} = 1$ in $F^*$\\
$\implies x^{p^n} = x \forall x \in F$ (a generalization of Little Fermat Theorem)

Very special polynomial $x^{p^n} - x \in \F_p[x]$ with degree $p^n$. It's roots are exactly elements of $F$, $|F| = p^n$

\begin{thm}
    Every field $F$ has an algebraic closure, $\overline{F}$: a field containing $F$, algebraic over $F$, and algebraically closed
\end{thm}

\begin{cor}
    $\F_p \subset \overline{F}$ algebraically closed and algebraic over $\F_p$
\end{cor}

$x^{p^n} - x \in \F_p[x] = \prod\limits_{i = 1}^{p^n}(x - \alpha_i), \alpha_i \in \overline{F_p}$

Claim: all of these roots are different.\\
Suppose we can factor $x^{p^n} - x = (x - \alpha_1)^2g(x) \in \overline{F_p}[x]$. Then take a derivative, $(x^{p^n} - x)' = 2(x - \alpha_1)g(x) + (x -\alpha)^2g'(x)$. But the right side is divisible by $x-\alpha_1$. Well, the left side is $p^nx^{p^n - 1} - 1 = -1$. If we plug in $x = \alpha_1$, we're left with $-1 = 0$, which is obviously a contradiction

Claim: $F = \{a_1, a_2, \ldots, a_{p^n}\}$ is a field, so then we have a field with $p^n$ elements.

$F \subset \overline{\F_p}$. Now we just have to check closures. Take $x, y \in F$. Then $(xy)^{p^n} = x^{p^n}y^{p^n} \implies xy \in F$

$(-x)^{p^n} = (-1)^{p^n}x^{p^n} = -x \implies -x \in F$

$(x + y)^p = x^p + y^p$, $(x + y)^{p^2} = [(x + y)^p]^p = (x^p)^p + (y^p)^p = x^{p^2} + y^{p^2}$. By induction, $(x + p)^{p^n} = [(x + y)^{p^{n-1}}]^p = x^{p^n} + y^{p^n}$

Summary $\F_p \subset F \subset \overline{\F_p}$. $F = \F_{p^n} = \F_q$ where $q = p^n$. Is exactly the set of roots of $x^{p^n} - x \in \F_p[x]$

\begin{thm}
    Let $F$ be a field with $p^n$ elements $\implies F = \F_p(\alpha)$ for some $\alpha \in F$
\end{thm}

\begin{cor}
    $F$ is isomorphic to $\F_p[x]/(f)$, where $(f)$ is the minimal polynomial of $\alpha$. In particular, we see that there exists an irreducible polynomial of degree $n$ in $\F_p[x]$
\end{cor}

In fact $F^*$ is cyclic. Take $\alpha \in F^*$ any generator, then $F^* = \{1, \alpha, \alpha^2, \ldots, \alpha^{p^n - 1}\} \implies F$ is the smallest field that contains $\alpha \implies F = \F(\alpha)$

The proof that $\Z_p^*$ works, because all we used was that the field is finite. If we assume $F^*$ not cyclic, then all elements have order strictly less than $p^n - 1$, but that can't happen since we have $p^n - 1$ roots

\begin{thm}
    If $E$ and $F$ are finite fields with $p^n$ elements, then they are isomorphic
\end{thm}
\textbf{Proof} Write $E = \F_p(\alpha)$ for $\alpha \in F$. $f(x) = irr(\alpha, \F_p$) irreducible of degree $n$. But we know that $\alpha^{p^n} = \alpha \implies \alpha$ is a root of $x^{p^n} - x =  0$, therefore $f(x)$ dividies $x^{p^n} - x$. 

Now consider $F$, $|F| = p^n$. $\forall x \in F \implies x^{p^n} - x = 0$. Well, this factors as $f(x)g(x)$. Has $p^n$ roots (all elements of $F$ are roots). So, there exists some element $\beta$ such that $f(\beta) = 0$ since $f$ has degree $n$

$\F_p \subset \F_p(\beta) \subset F$. deg$(\beta) = deg(f) = n \implies [F: \F_p] = [\F(\beta) : \F_p] \implies F = \F_p(\beta)$. So $E = \F_p(\alpha)$ and $F = \F_p(\beta)$, both of which have $f$ as their minimal polynomial. Therefore, $E \cong \F_p(\alpha) \cong \F_p[x]/(f) \cong \F_p(\beta) \cong F$

\begin{rmk}
    Can it happen that $\F_{p^n} \subset \F_{p^m}$?
\end{rmk}
Let's consider $F_{p^n}* \subset \F_{p^m}^*$, well the left is a cyclic group of order $p^n - 1$ and the right is a cyclic group of order $p^m - 1$. So we have $p^n - 1|p^m - 1$

Let's try long division. $p^m - 1 = p^{m-n}(p^n - 1) + p^{m-n} - 1$. Then we need $p^n - 1 | p^{m-n} - 1$

\begin{thm}
    $p^n - 1$ divides $p^m - 1$ if and only if $n | m$
\end{thm}
$n | m \iff n | m - n \implies$ Induction on $m \implies p^n - 1 | p^{m-n} - 1 \iff n | m$
\begin{cor}
    If $\F_{p^n} \subset \F_{p^m} \iff n | m$
\end{cor}

\section{Group Work 6}
\textbf{Group 2}
Let $ax^2 + bx + c$ be a quadratic equation ($a \neq 0)$ with coefficients in a field $K$ with characteristic $\neq 2$. 

(1) Show that the usual quadratic formula gives roots of the equation either in $K$ or in some field extension $F$ of $K$ such that $[F : K] = 2$

\textbf{Proof} $x = \dfrac{- b \pm \sqrt[]{b^2 - 4ac}}{2a}$. Because $a\neq 0, char(K) \neq 0$, we know that $2a \neq 0$

Case 1: $b^2 - 4ac = d^2, (d \in K)$ $x = - \dfrac{- b \pm d}{2a}$, so $x$ is in $K$

Case 2: $b^2 - 4ac \neq d^2$, take $x^2 - D$ where $D = b^2 - 4ac \in K$, then take the field extension $F(\alpha)$ where $\alpha^2 - D$. Then this is obviously degree two.

(2) Let $F$ be a field extension of $K$ such that $[F: K] = 2$ and $charK \neq 2$. Show that there exists $D \in K$ such that $F = K(\sqrt{D})$

\textbf{Proof} Let $\beta \in F, \beta \not \in K$. We now that $[F : K] = 2$, and $[K(\beta), K] > 1$. Then $[F: K] = [F : K(\beta)][K(\beta): K] = 2$, so $[F : K(\beta)]$ must be 1, and $F = K(\beta)$

$\beta$ is the solution to $ax^2 + bx + c = 0$, and $\beta = \dfrac{-b \pm \sqrt[]{b^2 - 4ac}}{2a} = \dfrac{-b \pm \sqrt[]{D}}{2a}$. Therefore, $\sqrt[]{D} \in K(\beta)$ and $K(\sqrt[]{D}) \subset K(\beta)$, therefore $K(\beta) = K(\sqrt[]{D})$. Therefore $F = K(\sqrt[]{D})$, and we are done.

(3) Show that (1) can fail if $charK = 2$
\textbf{Proof} $[\F_4 : \F_2] = 2$, but both of the elements of $\F_2$ have square roots, the quadratics are reducible

\textbf{Group A}
Let $F \subset K$ be a field extension and let $K_1, K_2 \subset K$ be subfields containing $F$, Let $K_1K_2 \subset K$ be the smallest subfield containing $K_1$ and $K_2$ Suppose $K_1$ and $K_2$ are algebraic over $F$

(1) Show that $K_1K_2$ is algebraic over $F$

\textbf{Proof}
Michael was mid proof and Tevelev went "Looks like an orgy of greek letters and summation signs" so we will do it next time

$Z$ and $k[X]$ where $k$ is a field are principle ideal domains. Both have long division. 

\begin{defn}
    An integral domain $D$ is a Euclidean domain if there exists a function (called norm) $v: D\setminus\{0\} \to \Z_{\geq 0}$, such that for every $a, b \in D$, either $a = bq$ or $a = bq + r$, where $v(r) < v(b)$, and $v(ab) \geq v(a)$
\end{defn}

\begin{exm*}
    $\Z$, $v(a) = |a|$
\end{exm*}

\begin{exm*}
    $k[X]$, $v(f)$ = degree
\end{exm*}

\begin{thm}
    Every Eucliean domain is a PID [and therefore a UFD]
\end{thm}
Take $I \subset D$ ideal. If $I = \{0\} \implies I$ is principal. $I \neq \{0\} \implies$ pick $a \in I$ to be the element of smallest norm.

Claim: $I = (a)$. Take $b \in I$. If $b = aq$, then great. If not, do $b = aq + r$, where $r$ has to have norm less than that norm of $r$, but $r = b - aq$, both of which are in the ideal, so we've found an element of norm smaller than $a$, contradiction.

\begin{exm*}
    Gaussian Integers $\Z[i] = \{a + bi: a, b \in \Z\}$
\end{exm*}
Forms a grid graphically. This is definitely a commutative ring with 1. $\Z[i] \subset \C$ subring, therefore it must be an integral domain.

Norm: $a^2 + b^2$. Take $\alpha, \beta \in \Z[i]$. Draw $(\beta) = \gamma\beta$ where $\gamma \in \Z[i]$. $\beta(a + bi) = a\beta + i b \beta$. Plot for all $a, b$

it could be the case that $\alpha$ is already onto the grid. If not, then $\alpha = \beta\gamma + \delta$ where $v(\delta) < v(\beta)$. So choose the square containing $\alpha$. Chose $\beta\gamma$ to be the vertex of the square that $\alpha$ is closest to. Then $|\delta| < |\beta|$ since $\beta$ is the side length. But quarter circles cover the square.
\end{document}